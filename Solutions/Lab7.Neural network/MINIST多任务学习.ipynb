{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Exercise 2  Handwriting recognition with MLP\n",
    "\n",
    "Like last week's lab , your task in this section is also about recognizing handwritten digits, but you are required to use MLP to complete the exercise. It is recommended that you define an MLP class, which is a subclass of `nn.module`.\n",
    "\n",
    "<font color='red' size=4>Note that your accuracy in this section will directly determine your score.</font>\n",
    "\n",
    "For this exercise we use the `minist` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "+ load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "########### Write Your Code Here ###########\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "train_data, test_data = [torchvision.datasets.MNIST(\n",
    "    root = './datasets/',  \n",
    "    train = trainOrNot,       \n",
    "    transform = torchvision.transforms.ToTensor(),   \n",
    "    download=True\n",
    ") for trainOrNot  in [True, False]]\n",
    "train_loader, test_loader = [DataLoader(data, batch_size=64, shuffle=False) for data in [train_data, test_data]]\n",
    "############################################                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\EnglishStandardPath\\DevProgramsFile\\Python\\python39\\lib\\site-packages\\torchvision\\datasets\\mnist.py:75: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "d:\\EnglishStandardPath\\DevProgramsFile\\Python\\python39\\lib\\site-packages\\torchvision\\datasets\\mnist.py:80: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1de737ab070>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data.train_data\n",
    "test_data.test_data\n",
    "# train_data, test_data\n",
    "trainfeature, trainlabel = next(iter(train_data))\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(trainfeature[0].detach().numpy(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "+ Define a MLP subclass of nn. Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3028, 0.3028, 0.3028, 0.3028, 0.3028, 0.3028, 0.3028, 0.3028, 0.3028,\n",
       "         0.3028]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########### Write Your Code Here ###########\n",
    "from torch import nn\n",
    "import torch\n",
    "import copy\n",
    "class ShareBottom(nn.Module):\n",
    "    \"\"\"\n",
    "    MMoE\n",
    "    多任务：10个数字是10个任务，独立去预测概率。最后概率最高的是答案。loss计算时用softmax+cross_entropy_loss，也可以不用。\n",
    "    多专家：4x4个专家，分管7x7的区域，做一个粗陋的卷积。\n",
    "    多门控\n",
    "    ShareBottom\n",
    "    Args:\n",
    "        nn (_type_): _description_\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 5), # in_channels, out_channels, kernel_size\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(2, 2), # kernel_size, stride\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        fc = nn.Sequential(\n",
    "            nn.Linear(16*4*4, 120),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(84, 1)\n",
    "        )\n",
    "        self.towers = nn.ModuleList([copy.deepcopy(fc) for _ in range(10)])\n",
    "    def forward(self, img):\n",
    "        feature = self.conv(img)\n",
    "        feature = feature.view(img.shape[0], -1)\n",
    "        out  = [tower(feature) for tower in self.towers]\n",
    "        return torch.cat(out, dim=1)\n",
    "        \n",
    "test_model = ShareBottom()\n",
    "test_X = torch.randn(1, 28, 28)\n",
    "test_y = test_model(test_X)\n",
    "test_y\n",
    "############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "+ Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShareBottom(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): Sigmoid()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): Sigmoid()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (towers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=120, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=120, out_features=84, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=84, out_features=1, bias=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=120, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=120, out_features=84, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=84, out_features=1, bias=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=120, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=120, out_features=84, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=84, out_features=1, bias=True)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=120, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=120, out_features=84, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=84, out_features=1, bias=True)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=120, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=120, out_features=84, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=84, out_features=1, bias=True)\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=120, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=120, out_features=84, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=84, out_features=1, bias=True)\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=120, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=120, out_features=84, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=84, out_features=1, bias=True)\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=120, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=120, out_features=84, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=84, out_features=1, bias=True)\n",
       "    )\n",
       "    (8): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=120, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=120, out_features=84, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=84, out_features=1, bias=True)\n",
       "    )\n",
       "    (9): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=120, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=120, out_features=84, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=84, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########### Write Your Code Here ###########\n",
    "mlp_clf = ShareBottom()\n",
    "mlp_clf\n",
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(mlp_clf.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\EnglishStandardPath\\DevProgramsFile\\Python\\python39\\lib\\site-packages\\torchvision\\datasets\\mnist.py:80: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for X, y in test_loader:\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    break\n",
    "test_data.test_data.data.shape\n",
    "test_data.test_data.data.reshape(10000, 1, 28, 28).shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    " + Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "########### Write Your Code Here ###########\n",
    "criteria = nn.CrossEntropyLoss()\n",
    "############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "+ The optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "########### Write Your Code Here ###########\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(mlp_clf.parameters(), lr=0.01)\n",
    "############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "+ training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 0.10692787915468216\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\EnglishStandardPath\\Practice_File\\22_fall\\P_Machine_Learning\\SUSTech-Machine-Learning-Lab-Solutions\\Solutions\\Lab7.Neural network\\MINIST多任务学习.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/EnglishStandardPath/Practice_File/22_fall/P_Machine_Learning/SUSTech-Machine-Learning-Lab-Solutions/Solutions/Lab7.Neural%20network/MINIST%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0.ipynb#X21sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         \u001b[39mif\u001b[39;00m epoch \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/EnglishStandardPath/Practice_File/22_fall/P_Machine_Learning/SUSTech-Machine-Learning-Lab-Solutions/Solutions/Lab7.Neural%20network/MINIST%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0.ipynb#X21sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mepoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m, loss \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m.\u001b[39mitem()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/EnglishStandardPath/Practice_File/22_fall/P_Machine_Learning/SUSTech-Machine-Learning-Lab-Solutions/Solutions/Lab7.Neural%20network/MINIST%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0.ipynb#X21sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m train_data_loader(mlp_clf, train_loader, optimizer, criteria)\n",
      "\u001b[1;32md:\\EnglishStandardPath\\Practice_File\\22_fall\\P_Machine_Learning\\SUSTech-Machine-Learning-Lab-Solutions\\Solutions\\Lab7.Neural network\\MINIST多任务学习.ipynb Cell 16\u001b[0m in \u001b[0;36mtrain_data_loader\u001b[1;34m(model, data_loader, optimizer, criteria, epochs)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/EnglishStandardPath/Practice_File/22_fall/P_Machine_Learning/SUSTech-Machine-Learning-Lab-Solutions/Solutions/Lab7.Neural%20network/MINIST%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m X, y \u001b[39min\u001b[39;00m data_loader:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/EnglishStandardPath/Practice_File/22_fall/P_Machine_Learning/SUSTech-Machine-Learning-Lab-Solutions/Solutions/Lab7.Neural%20network/MINIST%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/EnglishStandardPath/Practice_File/22_fall/P_Machine_Learning/SUSTech-Machine-Learning-Lab-Solutions/Solutions/Lab7.Neural%20network/MINIST%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m model(X)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/EnglishStandardPath/Practice_File/22_fall/P_Machine_Learning/SUSTech-Machine-Learning-Lab-Solutions/Solutions/Lab7.Neural%20network/MINIST%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0.ipynb#X21sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     loss \u001b[39m=\u001b[39m criteria(y_pred, y)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/EnglishStandardPath/Practice_File/22_fall/P_Machine_Learning/SUSTech-Machine-Learning-Lab-Solutions/Solutions/Lab7.Neural%20network/MINIST%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0.ipynb#X21sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32md:\\EnglishStandardPath\\DevProgramsFile\\Python\\python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32md:\\EnglishStandardPath\\Practice_File\\22_fall\\P_Machine_Learning\\SUSTech-Machine-Learning-Lab-Solutions\\Solutions\\Lab7.Neural network\\MINIST多任务学习.ipynb Cell 16\u001b[0m in \u001b[0;36mShareBottom.forward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/EnglishStandardPath/Practice_File/22_fall/P_Machine_Learning/SUSTech-Machine-Learning-Lab-Solutions/Solutions/Lab7.Neural%20network/MINIST%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0.ipynb#X21sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m feature \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv(img)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/EnglishStandardPath/Practice_File/22_fall/P_Machine_Learning/SUSTech-Machine-Learning-Lab-Solutions/Solutions/Lab7.Neural%20network/MINIST%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0.ipynb#X21sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m feature \u001b[39m=\u001b[39m feature\u001b[39m.\u001b[39mview(img\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/EnglishStandardPath/Practice_File/22_fall/P_Machine_Learning/SUSTech-Machine-Learning-Lab-Solutions/Solutions/Lab7.Neural%20network/MINIST%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0.ipynb#X21sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m out  \u001b[39m=\u001b[39m [tower(feature) \u001b[39mfor\u001b[39;00m tower \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtowers]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/EnglishStandardPath/Practice_File/22_fall/P_Machine_Learning/SUSTech-Machine-Learning-Lab-Solutions/Solutions/Lab7.Neural%20network/MINIST%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0.ipynb#X21sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(out, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;32md:\\EnglishStandardPath\\Practice_File\\22_fall\\P_Machine_Learning\\SUSTech-Machine-Learning-Lab-Solutions\\Solutions\\Lab7.Neural network\\MINIST多任务学习.ipynb Cell 16\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/EnglishStandardPath/Practice_File/22_fall/P_Machine_Learning/SUSTech-Machine-Learning-Lab-Solutions/Solutions/Lab7.Neural%20network/MINIST%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0.ipynb#X21sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m feature \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv(img)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/EnglishStandardPath/Practice_File/22_fall/P_Machine_Learning/SUSTech-Machine-Learning-Lab-Solutions/Solutions/Lab7.Neural%20network/MINIST%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0.ipynb#X21sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m feature \u001b[39m=\u001b[39m feature\u001b[39m.\u001b[39mview(img\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/EnglishStandardPath/Practice_File/22_fall/P_Machine_Learning/SUSTech-Machine-Learning-Lab-Solutions/Solutions/Lab7.Neural%20network/MINIST%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0.ipynb#X21sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m out  \u001b[39m=\u001b[39m [tower(feature) \u001b[39mfor\u001b[39;00m tower \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtowers]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/EnglishStandardPath/Practice_File/22_fall/P_Machine_Learning/SUSTech-Machine-Learning-Lab-Solutions/Solutions/Lab7.Neural%20network/MINIST%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0.ipynb#X21sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(out, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32md:\\EnglishStandardPath\\DevProgramsFile\\Python\\python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\EnglishStandardPath\\DevProgramsFile\\Python\\python39\\lib\\site-packages\\torch\\nn\\modules\\container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32md:\\EnglishStandardPath\\DevProgramsFile\\Python\\python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\EnglishStandardPath\\DevProgramsFile\\Python\\python39\\lib\\site-packages\\torch\\nn\\modules\\activation.py:290\u001b[0m, in \u001b[0;36mSigmoid.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 290\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49msigmoid(\u001b[39minput\u001b[39;49m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "########### Write Your Code Here ###########\n",
    "def train_data_loader(model, data_loader, optimizer, criteria, epochs=101):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for X, y in data_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X)\n",
    "            loss = criteria(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"epoch {epoch}, loss {loss.item()}\")\n",
    "train_data_loader(mlp_clf, train_loader, optimizer, criteria) #明智的选择是定义函数，而不是每次都写一遍\n",
    "############################################\n",
    "# 训练时间较长，后面我们存到了文件，可以直接加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Write Your Code Here ###########\n",
    "def meta_balance_train(model, data_loader, optimizer, prob_onehot_loss, epochs=101):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for X, y in data_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X)\n",
    "            y_prob = torch.softmax(y_pred, dim=1)\n",
    "            y_onehot = torch.zeros_like(y_prob)\n",
    "            y_onehot[:, y] = 1\n",
    "            losses = [prob_onehot_loss(y_prob[:, i], y_onehot) for i in range(10)]\n",
    "            def grad_norm(mod):\n",
    "                grad = [p.grad.flatten() for p in mod.parameters() if p.grad is not None]\n",
    "                c = torch.cat(grad)\n",
    "                return torch.norm(c)\n",
    "            # 不妨设主任务为0。\n",
    "            losses[0].backward()\n",
    "            G0 = grad_norm(model.conv)\n",
    "            for loss in losses[1:]:\n",
    "                \n",
    "                loss.backward()\n",
    "                G = grad_norm(model.conv)\n",
    "                \n",
    "                \n",
    "            optimizer.step()\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"epoch {epoch}, loss {loss.item()}\")\n",
    "meta_balance_train(mlp_clf, train_loader, optimizer, criteria) #明智的选择是定义函数，而不是每次都写一遍\n",
    "############################################\n",
    "# 训练时间较长，后面我们存到了文件，可以直接加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_clf.conv.parameters()\n",
    "mlp_clf.conv.zero_grad()\n",
    "grad = [p.grad.flatten() for p in mlp_clf.conv.parameters()]\n",
    "c = torch.cat(grad, dim=0)\n",
    "c.norm()\n",
    "# grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\EnglishStandardPath\\Practice_File\\22_fall\\P_Machine_Learning\\SUSTech-Machine-Learning-Lab-Solutions\\Solutions\\Lab7.Neural network\\MINIST多任务学习.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/EnglishStandardPath/Practice_File/22_fall/P_Machine_Learning/SUSTech-Machine-Learning-Lab-Solutions/Solutions/Lab7.Neural%20network/MINIST%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0.ipynb#X35sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m b\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/EnglishStandardPath/Practice_File/22_fall/P_Machine_Learning/SUSTech-Machine-Learning-Lab-Solutions/Solutions/Lab7.Neural%20network/MINIST%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0.ipynb#X35sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m a\u001b[39m.\u001b[39mgrad\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/EnglishStandardPath/Practice_File/22_fall/P_Machine_Learning/SUSTech-Machine-Learning-Lab-Solutions/Solutions/Lab7.Neural%20network/MINIST%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0.ipynb#X35sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m b\u001b[39m.\u001b[39;49msum()\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/EnglishStandardPath/Practice_File/22_fall/P_Machine_Learning/SUSTech-Machine-Learning-Lab-Solutions/Solutions/Lab7.Neural%20network/MINIST%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0.ipynb#X35sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m a\u001b[39m.\u001b[39mgrad\n",
      "File \u001b[1;32md:\\EnglishStandardPath\\DevProgramsFile\\Python\\python39\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32md:\\EnglishStandardPath\\DevProgramsFile\\Python\\python39\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 3, requires_grad=True)\n",
    "b = a*3\n",
    "b.sum().backward()\n",
    "a.grad\n",
    "b.sum().backward()\n",
    "a.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to share_bottom.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(mlp_clf.state_dict(), \"share_bottom.pth\")\n",
    "print(\"Saved PyTorch Model State to share_bottom.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ReallyDeepMLP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\EnglishStandardPath\\Practice_File\\22_fall\\P_Machine_Learning\\SUSTech-Machine-Learning-Lab-Solutions\\Solutions\\Lab7.Neural network\\MINIST多任务学习.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/EnglishStandardPath/Practice_File/22_fall/P_Machine_Learning/SUSTech-Machine-Learning-Lab-Solutions/Solutions/Lab7.Neural%20network/MINIST%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m mlp_clf \u001b[39m=\u001b[39m ReallyDeepMLP() \u001b[39m# 需要时同一个类型的model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/EnglishStandardPath/Practice_File/22_fall/P_Machine_Learning/SUSTech-Machine-Learning-Lab-Solutions/Solutions/Lab7.Neural%20network/MINIST%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m mlp_clf\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mnet.pth\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ReallyDeepMLP' is not defined"
     ]
    }
   ],
   "source": [
    "mlp_clf = ShareBottom() # 需要时同一个类型的model\n",
    "mlp_clf.load_state_dict(torch.load(\"share_bottom.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "+ Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\EnglishStandardPath\\DevProgramsFile\\Python\\python39\\lib\\site-packages\\torchvision\\datasets\\mnist.py:80: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "d:\\EnglishStandardPath\\DevProgramsFile\\Python\\python39\\lib\\site-packages\\torchvision\\datasets\\mnist.py:70: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n",
      "C:\\Users\\YeCanming\\AppData\\Local\\Temp\\ipykernel_30484\\3406663984.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  criteria(y_pred, torch.tensor(test_data.test_labels))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.2657, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########### Write Your Code Here ###########\n",
    "mlp_clf.eval()\n",
    "y_pred = mlp_clf(test_data.test_data.reshape(10000, 1, 28, 28).float())\n",
    "criteria(y_pred, torch.tensor(test_data.test_labels))\n",
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 10])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape\n",
    "# y_pred[0]\n",
    "# torch.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShareBottom accuracy = 0.9232\n",
      "fper=[0.00000000e+00 0.00000000e+00 0.00000000e+00 1.10864745e-04\n",
      " 1.10864745e-04 2.21729490e-04 2.21729490e-04 3.32594235e-04\n",
      " 3.32594235e-04 4.43458980e-04 4.43458980e-04 5.54323725e-04\n",
      " 5.54323725e-04 6.65188470e-04 6.65188470e-04 8.86917960e-04\n",
      " 8.86917960e-04 9.97782705e-04 9.97782705e-04 1.33037694e-03\n",
      " 1.33037694e-03 1.44124169e-03 1.44124169e-03 1.55210643e-03\n",
      " 1.55210643e-03 1.77383592e-03 1.77383592e-03 2.21729490e-03\n",
      " 2.21729490e-03 2.32815965e-03 2.32815965e-03 2.43902439e-03\n",
      " 2.43902439e-03 3.10421286e-03 3.10421286e-03 3.54767184e-03\n",
      " 3.54767184e-03 3.76940133e-03 3.76940133e-03 3.88026608e-03\n",
      " 3.88026608e-03 3.99113082e-03 3.99113082e-03 4.43458980e-03\n",
      " 4.43458980e-03 4.65631929e-03 4.65631929e-03 4.87804878e-03\n",
      " 4.87804878e-03 4.98891353e-03 4.98891353e-03 5.09977827e-03\n",
      " 5.09977827e-03 5.21064302e-03 5.21064302e-03 5.65410200e-03\n",
      " 5.65410200e-03 6.20842572e-03 6.20842572e-03 6.43015521e-03\n",
      " 6.43015521e-03 8.53658537e-03 8.53658537e-03 8.75831486e-03\n",
      " 8.75831486e-03 8.86917960e-03 8.86917960e-03 8.98004435e-03\n",
      " 8.98004435e-03 9.20177384e-03 9.20177384e-03 9.53436807e-03\n",
      " 9.53436807e-03 9.75609756e-03 9.75609756e-03 1.06430155e-02\n",
      " 1.06430155e-02 1.07538803e-02 1.07538803e-02 1.14190687e-02\n",
      " 1.14190687e-02 1.23059867e-02 1.23059867e-02 1.28603104e-02\n",
      " 1.28603104e-02 1.41906874e-02 1.41906874e-02 1.45232816e-02\n",
      " 1.45232816e-02 1.60753880e-02 1.60753880e-02 1.94013304e-02\n",
      " 1.94013304e-02 2.02882483e-02 2.02882483e-02 2.05099778e-02\n",
      " 2.05099778e-02 2.20620843e-02 2.20620843e-02 2.68292683e-02\n",
      " 2.68292683e-02 2.87139690e-02 2.87139690e-02 3.35920177e-02\n",
      " 3.35920177e-02 3.78048780e-02 3.78048780e-02 4.09090909e-02\n",
      " 4.09090909e-02 4.47893570e-02 4.47893570e-02 4.70066519e-02\n",
      " 4.70066519e-02 5.27716186e-02 5.27716186e-02 6.47450111e-02\n",
      " 6.47450111e-02 8.92461197e-02 8.92461197e-02 9.78935698e-02\n",
      " 9.78935698e-02 1.49002217e-01 1.49002217e-01 2.12416851e-01\n",
      " 2.12638581e-01 2.81818182e-01 2.82039911e-01 3.31263858e-01\n",
      " 3.31485588e-01 3.57538803e-01 3.57760532e-01 3.67849224e-01\n",
      " 3.68070953e-01 3.86141907e-01 3.86363636e-01 3.99002217e-01\n",
      " 3.99223947e-01 4.01219512e-01 4.01441242e-01 4.02217295e-01\n",
      " 4.02439024e-01 4.42017738e-01 4.42239468e-01 4.51995565e-01\n",
      " 4.52217295e-01 4.54323725e-01 4.54545455e-01 4.57538803e-01\n",
      " 4.57760532e-01 4.63747228e-01 4.63968958e-01 4.77937916e-01\n",
      " 4.78159645e-01 4.80931264e-01 4.81152993e-01 4.89467849e-01\n",
      " 4.89689579e-01 4.91463415e-01 4.91685144e-01 4.92239468e-01\n",
      " 4.92461197e-01 4.94567627e-01 4.94789357e-01 5.36917960e-01\n",
      " 5.37139690e-01 5.39356984e-01 5.39578714e-01 5.59866962e-01\n",
      " 5.60088692e-01 5.64301552e-01 5.64523282e-01 5.78270510e-01\n",
      " 5.78492239e-01 5.89246120e-01 5.89467849e-01 5.96119734e-01\n",
      " 5.96341463e-01 6.00554324e-01 6.00776053e-01 6.03325942e-01\n",
      " 6.03547672e-01 6.07982262e-01 6.08203991e-01 6.08980044e-01\n",
      " 6.09201774e-01 6.12971175e-01 6.13192905e-01 6.22616408e-01\n",
      " 6.22838137e-01 6.24168514e-01 6.24390244e-01 6.32372506e-01\n",
      " 6.32594235e-01 6.35476718e-01 6.35698448e-01 6.43237251e-01\n",
      " 6.43458980e-01 6.44900222e-01 6.45121951e-01 6.46341463e-01\n",
      " 6.46563193e-01 6.56873614e-01 6.57095344e-01 6.64745011e-01\n",
      " 6.64966741e-01 6.76385809e-01 6.76718404e-01 6.78824834e-01\n",
      " 6.79046563e-01 6.81374723e-01 6.81596452e-01 6.83259424e-01\n",
      " 6.83481153e-01 6.84368071e-01 6.84589800e-01 6.85144124e-01\n",
      " 6.85365854e-01 6.91463415e-01 6.91685144e-01 6.92461197e-01\n",
      " 6.92682927e-01 6.98669623e-01 6.98891353e-01 7.00665188e-01\n",
      " 7.00886918e-01 7.03769401e-01 7.03991131e-01 7.06873614e-01\n",
      " 7.07095344e-01 7.10088692e-01 7.10310421e-01 7.14079823e-01\n",
      " 7.14301552e-01 7.16962306e-01 7.17184035e-01 7.28603104e-01\n",
      " 7.28824834e-01 7.41906874e-01 7.42128603e-01 7.53547672e-01\n",
      " 7.53769401e-01 7.54212860e-01 7.54434590e-01 7.55210643e-01\n",
      " 7.55432373e-01 7.56541020e-01 7.56762749e-01 7.59312639e-01\n",
      " 7.59534368e-01 7.63192905e-01 7.63414634e-01 7.63858093e-01\n",
      " 7.64079823e-01 7.65853659e-01 7.66075388e-01 7.69290466e-01\n",
      " 7.69512195e-01 7.70509978e-01 7.70731707e-01 7.72172949e-01\n",
      " 7.72394678e-01 7.73946785e-01 7.74168514e-01 7.77050998e-01\n",
      " 7.77272727e-01 7.82705100e-01 7.82926829e-01 7.83370288e-01\n",
      " 7.83592018e-01 7.84589800e-01 7.84811530e-01 7.88137472e-01\n",
      " 7.88359202e-01 7.92128603e-01 7.92350333e-01 7.98780488e-01\n",
      " 7.99002217e-01 7.99113082e-01 7.99334812e-01 8.01219512e-01\n",
      " 8.01552106e-01 8.01995565e-01 8.02217295e-01 8.03880266e-01\n",
      " 8.04101996e-01 8.05432373e-01 8.05654102e-01 8.10864745e-01\n",
      " 8.11197339e-01 8.14745011e-01 8.14966741e-01 8.15631929e-01\n",
      " 8.15853659e-01 8.17405765e-01 8.17627494e-01 8.18070953e-01\n",
      " 8.18292683e-01 8.22172949e-01 8.22394678e-01 8.23059867e-01\n",
      " 8.23281596e-01 8.23725055e-01 8.24168514e-01 8.29046563e-01\n",
      " 8.29268293e-01 8.29711752e-01 8.29933481e-01 8.31374723e-01\n",
      " 8.31596452e-01 8.33924612e-01 8.34146341e-01 8.36917960e-01\n",
      " 8.37139690e-01 8.38359202e-01 8.38580931e-01 8.46008869e-01\n",
      " 8.46230599e-01 8.48115299e-01 8.48337029e-01 8.50110865e-01\n",
      " 8.50332594e-01 8.50443459e-01 8.50665188e-01 8.51330377e-01\n",
      " 8.51552106e-01 8.52549889e-01 8.52771619e-01 8.54323725e-01\n",
      " 8.54545455e-01 8.57317073e-01 8.57538803e-01 8.58869180e-01\n",
      " 8.59090909e-01 8.59977827e-01 8.60199557e-01 8.61862528e-01\n",
      " 8.62084257e-01 8.62971175e-01 8.63192905e-01 8.66518847e-01\n",
      " 8.66740576e-01 8.67073171e-01 8.67294900e-01 8.67738359e-01\n",
      " 8.67960089e-01 8.72283814e-01 8.72505543e-01 8.73059867e-01\n",
      " 8.73392461e-01 8.73725055e-01 8.73946785e-01 8.74722838e-01\n",
      " 8.74944568e-01 8.75277162e-01 8.75498891e-01 8.75720621e-01\n",
      " 8.75942350e-01 8.76385809e-01 8.76607539e-01 8.77937916e-01\n",
      " 8.78159645e-01 8.79711752e-01 8.79933481e-01 8.80155211e-01\n",
      " 8.80376940e-01 8.80931264e-01 8.81152993e-01 8.82372506e-01\n",
      " 8.82594235e-01 8.84146341e-01 8.84368071e-01 8.86141907e-01\n",
      " 8.86363636e-01 8.87583149e-01 8.87804878e-01 8.88359202e-01\n",
      " 8.88580931e-01 8.88913525e-01 8.89135255e-01 8.90354767e-01\n",
      " 8.90576497e-01 8.91463415e-01 8.91685144e-01 8.92572062e-01\n",
      " 8.92793792e-01 8.92904656e-01 8.93126386e-01 8.93458980e-01\n",
      " 8.93680710e-01 8.94345898e-01 8.94567627e-01 8.94789357e-01\n",
      " 8.95011086e-01 8.96452328e-01 8.96674058e-01 8.99445676e-01\n",
      " 8.99667406e-01 9.00332594e-01 9.00665188e-01 9.00997783e-01\n",
      " 9.01219512e-01 9.01330377e-01 9.01552106e-01 9.02328160e-01\n",
      " 9.02549889e-01 9.02882483e-01 9.03104213e-01 9.03436807e-01\n",
      " 9.03658537e-01 9.05099778e-01 9.05543237e-01 9.06208426e-01\n",
      " 9.06430155e-01 9.07206208e-01 9.07427938e-01 9.10421286e-01\n",
      " 9.10643016e-01 9.11086475e-01 9.11529933e-01 9.11862528e-01\n",
      " 9.12084257e-01 9.12860310e-01 9.13082040e-01 9.16297118e-01\n",
      " 9.16518847e-01 9.17738359e-01 9.17960089e-01 9.20953437e-01\n",
      " 9.21175166e-01 9.22394678e-01 9.22616408e-01 9.22838137e-01\n",
      " 9.23059867e-01 9.30376940e-01 9.30598670e-01 9.30820399e-01\n",
      " 9.31042129e-01 9.35809313e-01 9.36031042e-01 9.40687361e-01\n",
      " 9.40909091e-01 9.41019956e-01 9.41241685e-01 9.41906874e-01\n",
      " 9.42128603e-01 9.43458980e-01 9.43680710e-01 9.46008869e-01\n",
      " 9.46230599e-01 9.49002217e-01 9.49223947e-01 9.49556541e-01\n",
      " 9.49778271e-01 9.51330377e-01 9.51552106e-01 9.53104213e-01\n",
      " 9.53325942e-01 9.55432373e-01 9.55875831e-01 9.56097561e-01\n",
      " 9.56319290e-01 9.59201774e-01 9.59423503e-01 9.68403548e-01\n",
      " 9.68625277e-01 9.69290466e-01 9.69623060e-01 9.71951220e-01\n",
      " 9.72172949e-01 9.73725055e-01 9.73946785e-01 9.74279379e-01\n",
      " 9.74501109e-01 9.78824834e-01 9.79046563e-01 9.84589800e-01\n",
      " 9.84811530e-01 9.85365854e-01 9.85587583e-01 9.89800443e-01\n",
      " 9.90022173e-01 1.00000000e+00], tper=[0.         0.00102041 0.5        0.5        0.79795918 0.79795918\n",
      " 0.87142857 0.87142857 0.8744898  0.8744898  0.87653061 0.87653061\n",
      " 0.90102041 0.90102041 0.9122449  0.9122449  0.92040816 0.92040816\n",
      " 0.9244898  0.9244898  0.92653061 0.92653061 0.93163265 0.93163265\n",
      " 0.93367347 0.93367347 0.9377551  0.9377551  0.94285714 0.94285714\n",
      " 0.94387755 0.94387755 0.94489796 0.94489796 0.94591837 0.94591837\n",
      " 0.94693878 0.94693878 0.94795918 0.94795918 0.95       0.95\n",
      " 0.95102041 0.95102041 0.95204082 0.95204082 0.95306122 0.95306122\n",
      " 0.95510204 0.95510204 0.95714286 0.95714286 0.95816327 0.95816327\n",
      " 0.95918367 0.95918367 0.9622449  0.9622449  0.96326531 0.96326531\n",
      " 0.96632653 0.96632653 0.96734694 0.96734694 0.96836735 0.96836735\n",
      " 0.96938776 0.96938776 0.97142857 0.97142857 0.97244898 0.97244898\n",
      " 0.97346939 0.97346939 0.9744898  0.9744898  0.9755102  0.9755102\n",
      " 0.97653061 0.97653061 0.97755102 0.97755102 0.97857143 0.97857143\n",
      " 0.97959184 0.97959184 0.98061224 0.98061224 0.98163265 0.98163265\n",
      " 0.98265306 0.98265306 0.98367347 0.98367347 0.98469388 0.98469388\n",
      " 0.98571429 0.98571429 0.98673469 0.98673469 0.98877551 0.98877551\n",
      " 0.98979592 0.98979592 0.99081633 0.99081633 0.99183673 0.99183673\n",
      " 0.99285714 0.99285714 0.99387755 0.99387755 0.99489796 0.99489796\n",
      " 0.99591837 0.99591837 0.99693878 0.99693878 0.99795918 0.99795918\n",
      " 0.99897959 0.99897959 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.        ], thresholds=[ 7.806894    6.806894    6.167357    6.167066    5.380076    5.3759456\n",
      "  4.8238463   4.8090606   4.793086    4.78314     4.7687845   4.750482\n",
      "  4.3975716   4.3801427   4.26009     4.219986    4.1250834   4.1199746\n",
      "  4.050984    4.0181837   3.994434    3.9939692   3.9463904   3.9210703\n",
      "  3.9160297   3.8973014   3.84068     3.805897    3.7502444   3.7494721\n",
      "  3.7446468   3.7154348   3.713834    3.673884    3.658597    3.614586\n",
      "  3.608283    3.5968878   3.57402     3.5329268   3.5033538   3.499256\n",
      "  3.4912612   3.4400373   3.4191353   3.413329    3.403683    3.347796\n",
      "  3.340017    3.3318384   3.2910473   3.2846699   3.2730708   3.269609\n",
      "  3.2620313   3.1584604   3.118401    3.011484    2.914678    2.900327\n",
      "  2.8258142   2.5344949   2.5173862   2.4928372   2.4918306   2.4866161\n",
      "  2.4859877   2.484737    2.4723036   2.4431698   2.433658    2.3753972\n",
      "  2.354899    2.272204    2.2608593   2.0733817   2.0254204   2.0214589\n",
      "  2.018596    1.9477316   1.9099287   1.706736    1.6858951   1.632325\n",
      "  1.6281184   1.4472657   1.440653    1.3995466   1.3948561   1.182487\n",
      "  1.1632338   0.73014754  0.7245767   0.6445874   0.6371013   0.63236403\n",
      "  0.62110895  0.42203677  0.39596534 -0.079264   -0.09683286 -0.2686923\n",
      " -0.27132124 -0.79470515 -0.8073392  -1.1456375  -1.1666772  -1.3574301\n",
      " -1.3585812  -1.5536495  -1.5566155  -1.6483911  -1.6554675  -1.9743717\n",
      " -1.9786991  -2.4133399  -2.4140031  -2.9245408  -2.925015   -3.0148246\n",
      " -3.015198   -3.294419   -3.2944372  -3.3892572  -3.3894427  -3.421827\n",
      " -3.4218276  -3.4335666  -3.4335828  -3.4393525  -3.4393551  -3.4413183\n",
      " -3.4413211  -3.4444492  -3.444472   -3.4469671  -3.4470031  -3.4472272\n",
      " -3.4472501  -3.4473886  -3.4473937  -3.453354   -3.453373   -3.4549763\n",
      " -3.4549768  -3.4552157  -3.4552186  -3.4557087  -3.4557135  -3.4565008\n",
      " -3.4565182  -3.4582746  -3.4582832  -3.45858    -3.4585874  -3.45961\n",
      " -3.4597044  -3.4599655  -3.4600043  -3.460052   -3.4600565  -3.4603455\n",
      " -3.4603498  -3.4651382  -3.4651482  -3.4653523  -3.4653904  -3.467365\n",
      " -3.467367   -3.467737   -3.467746   -3.4691179  -3.469135   -3.4699132\n",
      " -3.4699168  -3.4704854  -3.4704945  -3.4707897  -3.4707987  -3.4709337\n",
      " -3.4709346  -3.471256   -3.4712727  -3.4713614  -3.4713748  -3.4716775\n",
      " -3.4716856  -3.4723728  -3.4723742  -3.4724758  -3.4725     -3.4730933\n",
      " -3.4730945  -3.473254   -3.4732645  -3.4738085  -3.473819   -3.4738896\n",
      " -3.4738925  -3.4739835  -3.4739845  -3.4746253  -3.4746258  -3.475149\n",
      " -3.4751494  -3.4757113  -3.4757307  -3.4758425  -3.475845   -3.4759881\n",
      " -3.475996   -3.476158   -3.4761612  -3.4762084  -3.4762099  -3.4762304\n",
      " -3.4762354  -3.4765074  -3.4765096  -3.476534   -3.4765341  -3.4768815\n",
      " -3.4768894  -3.4769423  -3.4769533  -3.4771252  -3.477136   -3.477276\n",
      " -3.4772856  -3.4774024  -3.477413   -3.4775777  -3.4775903  -3.4776952\n",
      " -3.4777057  -3.478234   -3.4782364  -3.4787085  -3.4787147  -3.479137\n",
      " -3.4791381  -3.4791448  -3.4791472  -3.479179   -3.4791849  -3.47921\n",
      " -3.4792137  -3.47932    -3.479326   -3.4794283  -3.4794304  -3.4794495\n",
      " -3.4794571  -3.479521   -3.4795234  -3.4796422  -3.4796445  -3.4796894\n",
      " -3.4796903  -3.479727   -3.4797351  -3.47977    -3.4797702  -3.4798577\n",
      " -3.479862   -3.4800165  -3.4800193  -3.4800332  -3.4800346  -3.4800644\n",
      " -3.480065   -3.480183   -3.4801862  -3.4802868  -3.4802918  -3.48047\n",
      " -3.4804704  -3.4804742  -3.48048    -3.480533   -3.4805348  -3.480549\n",
      " -3.480551   -3.4805803  -3.480581   -3.4806228  -3.480624   -3.4807749\n",
      " -3.480777   -3.4808676  -3.4808733  -3.4808915  -3.4808924  -3.480936\n",
      " -3.4809368  -3.4809437  -3.4809482  -3.4810333  -3.481034   -3.481051\n",
      " -3.4810545  -3.4810624  -3.4810674  -3.481206   -3.48121    -3.4812186\n",
      " -3.4812193  -3.48125    -3.481252   -3.4813187  -3.4813192  -3.481368\n",
      " -3.4813726  -3.48139    -3.4813912  -3.481547   -3.481552   -3.4815743\n",
      " -3.4815748  -3.4816172  -3.4816227  -3.4816232  -3.481629   -3.4816365\n",
      " -3.4816377  -3.4816506  -3.4816544  -3.4816806  -3.4816878  -3.4817536\n",
      " -3.4817545  -3.4817765  -3.481777   -3.4817903  -3.4817936  -3.4818256\n",
      " -3.4818275  -3.4818451  -3.481848   -3.481909   -3.4819117  -3.4819145\n",
      " -3.4819162  -3.4819214  -3.4819233  -3.4820132  -3.4820142  -3.4820268\n",
      " -3.4820306  -3.482034   -3.4820435  -3.4820557  -3.482062   -3.482069\n",
      " -3.4820702  -3.4820745  -3.482076   -3.4820797  -3.4820821  -3.482103\n",
      " -3.4821088  -3.4821455  -3.4821475  -3.4821494  -3.482155   -3.4821668\n",
      " -3.4821732  -3.482194   -3.4821959  -3.4822261  -3.4822266  -3.4822547\n",
      " -3.48226    -3.482278   -3.482282   -3.482291   -3.4822915  -3.4822986\n",
      " -3.4823015  -3.4823241  -3.4823258  -3.4823368  -3.4823372  -3.482364\n",
      " -3.482365   -3.482366   -3.4823673  -3.4823732  -3.4823754  -3.4823952\n",
      " -3.4823966  -3.4824038  -3.4824045  -3.4824193  -3.4824216  -3.4824722\n",
      " -3.4824727  -3.4824898  -3.4824917  -3.4824944  -3.482495   -3.4824958\n",
      " -3.482496   -3.4825118  -3.482512   -3.4825158  -3.482516   -3.4825184\n",
      " -3.4825194  -3.4825494  -3.482557   -3.4825644  -3.4825666  -3.4825797\n",
      " -3.48258    -3.4826267  -3.4826272  -3.4826338  -3.4826353  -3.4826386\n",
      " -3.4826415  -3.4826567  -3.4826584  -3.4827259  -3.4827278  -3.4827445\n",
      " -3.482745   -3.4827895  -3.4827898  -3.4828074  -3.4828079  -3.4828126\n",
      " -3.4828131  -3.4829242  -3.4829247  -3.48293    -3.4829316  -3.4830005\n",
      " -3.4830012  -3.4830828  -3.4830837  -3.483089   -3.483092   -3.483105\n",
      " -3.4831054  -3.483135   -3.4831364  -3.483187   -3.4831917  -3.4832761\n",
      " -3.4832776  -3.4832847  -3.4832861  -3.4833238  -3.4833262  -3.4833634\n",
      " -3.4833639  -3.4834044  -3.4834101  -3.4834137  -3.4834335  -3.4835026\n",
      " -3.483503   -3.483732   -3.483738   -3.4837549  -3.4837554  -3.4838398\n",
      " -3.4838417  -3.483876   -3.4838774  -3.4838865  -3.483894   -3.4840443\n",
      " -3.4840467  -3.4843073  -3.4843142  -3.4843352  -3.4843428  -3.4847162\n",
      " -3.4847205  -3.4901412 ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fast_evaluation import *\n",
    "evaluate_multiclass2(mlp_clf, y_pred.detach().numpy(), test_data.test_labels.detach().numpy())\n",
    "# 可见，测试集准确率达到96.59%。对0的分类的ROC曲线可以画出来："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Exercise 3  Questions (10 points )\n",
    "1.What's the difference between logistic regression and Perceptron?\n",
    "\n",
    "2.Advantages and disadvantages of neural networks?\n",
    "\n",
    "3.What is the role of Activation Function in Neural networks?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ddb042b13f5e38f5a1f3a81e594e2d461f8b2dedf72148cffbd195c398cb4bc9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

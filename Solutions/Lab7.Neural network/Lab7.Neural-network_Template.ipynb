{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB7 Assignment\n",
    "> The document description are designed by JIa Yanhong in 2022. Oct. 20th\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB Assignment\n",
    "### Exercise 1 logistic regression (20 points )\n",
    "This exercise uses dataset digit01.csv , which has 13 columns, and the last column is the dependent variable. \n",
    "\n",
    "This part requires you to implement a `logistic regression` using the pytorch framework (defining a logistic regression class that inherits `nn.module`). To test your model, we provide a dataset `digit01.csv` which is in the **datasets folder**. This dataset requires you to divide the training set and the test set by yourself, and it is recommended that 80% of the training set and 20% of the test set be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   10  11  12\n",
       "0   1   1   1   1   0   1   1   0   1   1   1   1   0\n",
       "1   0   1   1   1   0   1   1   0   1   1   1   1   0\n",
       "2   1   1   0   1   0   1   1   0   1   1   1   1   0\n",
       "3   1   1   1   1   0   1   1   0   1   1   1   0   0\n",
       "4   1   1   1   1   0   1   1   0   1   0   1   1   0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########### Write Your Code Here ###########\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"./datasets/digit01.csv\", header=None)\n",
    "df.head()\n",
    "############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "+ Splitting dataset into 80% Training and 20% Testing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(51, 12), (13, 12), (51,), (13,)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########### Write Your Code Here ###########\n",
    "X =df.iloc[:,:-1].values\n",
    "y = df.iloc[:,-1].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=112)\n",
    "[i.shape for i in (X_train, X_test, y_train, y_test)]\n",
    "############################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "+ Define a LogisticRegression subclass of nn. Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2305],\n",
       "        [0.8854],\n",
       "        [0.9198],\n",
       "        [0.7813],\n",
       "        [0.7757],\n",
       "        [0.6992],\n",
       "        [0.8828],\n",
       "        [0.0649],\n",
       "        [0.9971],\n",
       "        [0.5943]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a LogisticRegression subclass of nn. Module.\n",
    "########### Write Your Code Here ###########\n",
    "import torch\n",
    "from torch import nn\n",
    "class LogisticRegressionForBinaryClassification(nn.Module):\n",
    "    \"\"\"对数几率回归（不要翻译为逻辑回归，这没有任何逻辑）\n",
    "    几率和概率的关系是 几率 l = p/(1-p)\n",
    "    对数几率为 ln(l) = ln(p/(1-p)) = ln(p) - ln(1-p)\n",
    "    使用线性回归预测对数几率，然后使用sigmoid函数将预测值转换为概率，这就是对数几率回归\n",
    "    y = sigmoid(X @ W + b) <=> ln(y/(1-y)) = X @ W + b\n",
    "    \"\"\"\n",
    "    def __init__(self, input_features):\n",
    "        super().__init__() # 就应该这样写，写成super(LogisticRegressionForBinaryClassification， self)简直太傻了\n",
    "        out_features = 1\n",
    "        # xaviever = np.sqrt(2/(input_features+out_features))\n",
    "        xaviever = 1\n",
    "        self.W = nn.Parameter(torch.randn(input_features, out_features)\n",
    "                                          *xaviever)\n",
    "        self.b = nn.Parameter(torch.randn(1,out_features))\n",
    "        # 这里我们尝试不用nn.Linear, 搞明白一般来说自己应该怎么定义可训练参数。\n",
    "    def forward(self, X):\n",
    "        # input shape: (batch_size, input_features)\n",
    "        logits = X @ self.W + self.b # output shape: (batch_size, 1)\n",
    "        out = torch.sigmoid(logits) # 1/(1+exp(-logits)) https://pytorch.org/docs/stable/special.html#torch.special.expit\n",
    "        return out\n",
    "############################################\n",
    "test_X = torch.randn(10, 5)\n",
    "test_model = LogisticRegressionForBinaryClassification(5)\n",
    "test_y = test_model(test_X)\n",
    "test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "+ Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.3964],\n",
       "         [-1.1124],\n",
       "         [-1.2524],\n",
       "         [ 1.0556],\n",
       "         [-0.7752],\n",
       "         [ 0.6146],\n",
       "         [ 0.2815],\n",
       "         [ 0.9958],\n",
       "         [ 0.1683],\n",
       "         [ 0.2903],\n",
       "         [ 0.3655],\n",
       "         [-1.1022]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.5736]], requires_grad=True)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "########### Write Your Code Here ###########\n",
    "lr4clf = LogisticRegressionForBinaryClassification(X_train.shape[1])\n",
    "list(lr4clf.parameters())\n",
    "############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    " + Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2862e-05)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########### Write Your Code Here ###########\n",
    "from torch import optim\n",
    "# criteria = nn.CrossEntropyLoss() # 不能用这个，这个的话网络的输出是logits。我们的网络的输出是概率\n",
    "def cross_entropy_loss(y_pred, y_true, relax=1e-6):\n",
    "    y_pred = torch.Tensor(y_pred)\n",
    "    y_true = torch.Tensor(y_true)\n",
    "    upper = 1+relax\n",
    "    lower = 0-relax # 防止log(0)的出现\n",
    "    return -torch.mean((y_true-lower)*torch.log(y_pred-lower) + (upper-y_true)*torch.log(upper-y_pred))\n",
    "cross_entropy_loss(torch.tensor([1, 1, 1, 1, 1, 1]), torch.tensor([0, 0, 0, 0, 0, 0])) # 最大16左右\n",
    "cross_entropy_loss(torch.zeros(6), torch.ones(6)) # 最大16左右\n",
    "cross_entropy_loss(torch.zeros(6), torch.zeros(6)) \n",
    "############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "+ The optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "########### Write Your Code Here ###########\n",
    "optimizer = optim.SGD(lr4clf.parameters(), lr=0.01)\n",
    "############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "+ training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 0.09115996956825256\n",
      "epoch 10, loss 0.0907234475016594\n",
      "epoch 20, loss 0.09029164165258408\n",
      "epoch 30, loss 0.08986447751522064\n",
      "epoch 40, loss 0.08944187313318253\n",
      "epoch 50, loss 0.08902374655008316\n",
      "epoch 60, loss 0.08861002326011658\n",
      "epoch 70, loss 0.08820066601037979\n",
      "epoch 80, loss 0.08779556304216385\n",
      "epoch 90, loss 0.08739465475082397\n",
      "epoch 100, loss 0.08699791878461838\n",
      "epoch 110, loss 0.0866052433848381\n",
      "epoch 120, loss 0.08621659129858017\n",
      "epoch 130, loss 0.08583186566829681\n",
      "epoch 140, loss 0.08545105159282684\n",
      "epoch 150, loss 0.0850740522146225\n",
      "epoch 160, loss 0.08470083028078079\n",
      "epoch 170, loss 0.08433131873607635\n",
      "epoch 180, loss 0.0839654728770256\n",
      "epoch 190, loss 0.08360322564840317\n",
      "epoch 200, loss 0.08324453234672546\n"
     ]
    }
   ],
   "source": [
    "########### Write Your Code Here ###########\n",
    "def train(model, X, y, optimizer, criteria, epochs=201):\n",
    "    model.train()\n",
    "    X = torch.tensor(X, dtype=torch.float32)\n",
    "    y = torch.tensor(y, dtype=torch.float32).reshape(-1,1)\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X)\n",
    "        loss = criteria(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"epoch {epoch}, loss {loss.item()}\")\n",
    "train(lr4clf, X_train, y_train, optimizer, cross_entropy_loss)\n",
    "############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "+ Model Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.4847)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########### Write Your Code Here ###########\n",
    "def predict(model, X):\n",
    "    model.eval()\n",
    "    X = torch.tensor(X, dtype=torch.float32)\n",
    "    y_pred = model(X)\n",
    "    y_pred = y_pred.detach().numpy()\n",
    "    # y_pred = np.where(y_pred>=0.5, 1, 0)\n",
    "    y_predicted_cls = (y_pred>=0.5).astype(int)\n",
    "    return y_predicted_cls\n",
    "y_predicted_cls = predict(lr4clf, X_test)\n",
    "cross_entropy_loss(torch.tensor(y_predicted_cls), torch.tensor(y_test))\n",
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00        13\n",
      "   macro avg       1.00      1.00      1.00        13\n",
      "weighted avg       1.00      1.00      1.00        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_predicted_cls))\n",
    "# 可以看到效果非常好，达到100%的准确率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Exercise 2  Handwriting recognition with MLP\n",
    "\n",
    "Like last week's lab , your task in this section is also about recognizing handwritten digits, but you are required to use MLP to complete the exercise. It is recommended that you define an MLP class, which is a subclass of `nn.module`.\n",
    "\n",
    "<font color='red' size=4>Note that your accuracy in this section will directly determine your score.</font>\n",
    "\n",
    "For this exercise we use the `minist` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "+ load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "########### Write Your Code Here ###########\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "train_data, test_data = [torchvision.datasets.MNIST(\n",
    "    root = './datasets/',  \n",
    "    train = trainOrNot,       \n",
    "    transform = torchvision.transforms.ToTensor(),   \n",
    "    download=True\n",
    ") for trainOrNot  in [True, False]]\n",
    "train_loader, test_loader = [DataLoader(data, batch_size=64, shuffle=False) for data in [train_data, test_data]]\n",
    "############################################                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\EnglishStandardPath\\DevProgramsFile\\Python\\python39\\lib\\site-packages\\torchvision\\datasets\\mnist.py:75: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "d:\\EnglishStandardPath\\DevProgramsFile\\Python\\python39\\lib\\site-packages\\torchvision\\datasets\\mnist.py:80: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f9152ca970>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAAsTAAALEwEAmpwYAAAN8klEQVR4nO3df6jVdZ7H8ddrbfojxzI39iZOrWOEUdE6i9nSyjYRTj8o7FYMIzQ0JDl/JDSwyIb7xxSLIVu6rBSDDtXYMus0UJHFMNVm5S6BdDMrs21qoxjlphtmmv1a9b1/3K9xp+75nOs53/PD+34+4HDO+b7P93zffPHl99f53o8jQgAmvj/rdQMAuoOwA0kQdiAJwg4kQdiBJE7o5sJsc+of6LCI8FjT29qy277C9lu237F9ezvfBaCz3Op1dtuTJP1B0gJJOyW9JGlRROwozMOWHeiwTmzZ50l6JyLejYgvJf1G0sI2vg9AB7UT9hmS/jjq/c5q2p+wvcT2kO2hNpYFoE0dP0EXEeskrZPYjQd6qZ0t+y5JZ4x6/51qGoA+1E7YX5J0tu3v2j5R0o8kbaynLQB1a3k3PiIO2V4q6SlJkyQ9EBFv1NYZgFq1fOmtpYVxzA50XEd+VAPg+EHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEi0P2Yzjw6RJk4r1U045paPLX7p0acPaSSedVJx39uzZxfqtt95arN9zzz0Na4sWLSrO+/nnnxfrK1euLNbvvPPOYr0X2gq77fckHZB0WNKhiJhbR1MA6lfHlv3SiPiwhu8B0EEcswNJtBv2kPS07ZdtLxnrA7aX2B6yPdTmsgC0od3d+PkRscv2X0h6xvZ/R8Tm0R+IiHWS1kmS7WhzeQBa1NaWPSJ2Vc97JD0maV4dTQGoX8thtz3Z9pSjryX9QNL2uhoDUK92duMHJD1m++j3/HtE/L6WriaYM888s1g/8cQTi/WLL764WJ8/f37D2tSpU4vzXn/99cV6L+3cubNYX7NmTbE+ODjYsHbgwIHivK+++mqx/sILLxTr/ajlsEfEu5L+qsZeAHQQl96AJAg7kARhB5Ig7EAShB1IwhHd+1HbRP0F3Zw5c4r1TZs2Feudvs20Xx05cqRYv/nmm4v1Tz75pOVlDw8PF+sfffRRsf7WW2+1vOxOiwiPNZ0tO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwXX2GkybNq1Y37JlS7E+a9asOtupVbPe9+3bV6xfeumlDWtffvllcd6svz9oF9fZgeQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJhmyuwd69e4v1ZcuWFetXX311sf7KK68U683+pHLJtm3bivUFCxYU6wcPHizWzzvvvIa12267rTgv6sWWHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeS4H72PnDyyScX682GF167dm3D2uLFi4vz3njjjcX6hg0binX0n5bvZ7f9gO09trePmjbN9jO2366eT62zWQD1G89u/K8kXfG1abdLejYizpb0bPUeQB9rGvaI2Czp678HXShpffV6vaRr620LQN1a/W38QEQcHSzrA0kDjT5oe4mkJS0uB0BN2r4RJiKidOItItZJWidxgg7opVYvve22PV2Squc99bUEoBNaDftGSTdVr2+S9Hg97QDolKa78bY3SPq+pNNs75T0c0krJf3W9mJJ70v6YSebnOj279/f1vwff/xxy/PecsstxfrDDz9crDcbYx39o2nYI2JRg9JlNfcCoIP4uSyQBGEHkiDsQBKEHUiCsANJcIvrBDB58uSGtSeeeKI47yWXXFKsX3nllcX6008/Xayj+xiyGUiOsANJEHYgCcIOJEHYgSQIO5AEYQeS4Dr7BHfWWWcV61u3bi3W9+3bV6w/99xzxfrQ0FDD2n333Vect5v/NicSrrMDyRF2IAnCDiRB2IEkCDuQBGEHkiDsQBJcZ09ucHCwWH/wwQeL9SlTprS87OXLlxfrDz30ULE+PDxcrGfFdXYgOcIOJEHYgSQIO5AEYQeSIOxAEoQdSILr7Cg6//zzi/XVq1cX65dd1vpgv2vXri3WV6xYUazv2rWr5WUfz1q+zm77Adt7bG8fNe0O27tsb6seV9XZLID6jWc3/leSrhhj+r9ExJzq8bt62wJQt6Zhj4jNkvZ2oRcAHdTOCbqltl+rdvNPbfQh20tsD9lu/MfIAHRcq2H/haSzJM2RNCxpVaMPRsS6iJgbEXNbXBaAGrQU9ojYHRGHI+KIpF9KmldvWwDq1lLYbU8f9XZQ0vZGnwXQH5peZ7e9QdL3JZ0mabekn1fv50gKSe9J+mlENL25mOvsE8/UqVOL9WuuuaZhrdm98vaYl4u/smnTpmJ9wYIFxfpE1eg6+wnjmHHRGJPvb7sjAF3Fz2WBJAg7kARhB5Ig7EAShB1Igltc0TNffPFFsX7CCeWLRYcOHSrWL7/88oa1559/vjjv8Yw/JQ0kR9iBJAg7kARhB5Ig7EAShB1IgrADSTS96w25XXDBBcX6DTfcUKxfeOGFDWvNrqM3s2PHjmJ98+bNbX3/RMOWHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeS4Dr7BDd79uxifenSpcX6ddddV6yffvrpx9zTeB0+fLhYHx4u//XyI0eO1NnOcY8tO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwXX240Cza9mLFo010O6IZtfRZ86c2UpLtRgaGirWV6xYUaxv3LixznYmvKZbdttn2H7O9g7bb9i+rZo+zfYztt+unk/tfLsAWjWe3fhDkv4+Is6V9DeSbrV9rqTbJT0bEWdLerZ6D6BPNQ17RAxHxNbq9QFJb0qaIWmhpPXVx9ZLurZDPQKowTEds9ueKel7krZIGoiIoz9O/kDSQIN5lkha0kaPAGow7rPxtr8t6RFJP4uI/aNrMTI65JiDNkbEuoiYGxFz2+oUQFvGFXbb39JI0H8dEY9Wk3fbnl7Vp0va05kWAdSh6W68bUu6X9KbEbF6VGmjpJskrayeH+9IhxPAwMCYRzhfOffcc4v1e++9t1g/55xzjrmnumzZsqVYv/vuuxvWHn+8/E+GW1TrNZ5j9r+V9GNJr9veVk1brpGQ/9b2YknvS/phRzoEUIumYY+I/5I05uDuki6rtx0AncLPZYEkCDuQBGEHkiDsQBKEHUiCW1zHadq0aQ1ra9euLc47Z86cYn3WrFmttFSLF198sVhftWpVsf7UU08V65999tkx94TOYMsOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0mkuc5+0UUXFevLli0r1ufNm9ewNmPGjJZ6qsunn37asLZmzZrivHfddVexfvDgwZZ6Qv9hyw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSaS5zj44ONhWvR07duwo1p988sli/dChQ8V66Z7zffv2FedFHmzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJR0T5A/YZkh6SNCApJK2LiH+1fYekWyT9b/XR5RHxuybfVV4YgLZFxJijLo8n7NMlTY+IrbanSHpZ0rUaGY/9k4i4Z7xNEHag8xqFfTzjsw9LGq5eH7D9pqTe/mkWAMfsmI7Zbc+U9D1JW6pJS22/ZvsB26c2mGeJ7SHbQ+21CqAdTXfjv/qg/W1JL0haERGP2h6Q9KFGjuP/SSO7+jc3+Q5244EOa/mYXZJsf0vSk5KeiojVY9RnSnoyIs5v8j2EHeiwRmFvuhtv25Lul/Tm6KBXJ+6OGpS0vd0mAXTOeM7Gz5f0n5Jel3Skmrxc0iJJczSyG/+epJ9WJ/NK38WWHeiwtnbj60LYgc5reTcewMRA2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSKLbQzZ/KOn9Ue9Pq6b1o37trV/7kuitVXX29peNCl29n/0bC7eHImJuzxoo6Nfe+rUvid5a1a3e2I0HkiDsQBK9Dvu6Hi+/pF9769e+JHprVVd66+kxO4Du6fWWHUCXEHYgiZ6E3fYVtt+y/Y7t23vRQyO237P9uu1tvR6frhpDb4/t7aOmTbP9jO23q+cxx9jrUW932N5Vrbtttq/qUW9n2H7O9g7bb9i+rZre03VX6Ksr663rx+y2J0n6g6QFknZKeknSoojY0dVGGrD9nqS5EdHzH2DY/jtJn0h66OjQWrb/WdLeiFhZ/Ud5akT8Q5/0doeOcRjvDvXWaJjxn6iH667O4c9b0Yst+zxJ70TEuxHxpaTfSFrYgz76XkRslrT3a5MXSlpfvV6vkX8sXdegt74QEcMRsbV6fUDS0WHGe7ruCn11RS/CPkPSH0e936n+Gu89JD1t+2XbS3rdzBgGRg2z9YGkgV42M4amw3h309eGGe+bddfK8Oft4gTdN82PiL+WdKWkW6vd1b4UI8dg/XTt9BeSztLIGIDDklb1splqmPFHJP0sIvaPrvVy3Y3RV1fWWy/CvkvSGaPef6ea1hciYlf1vEfSYxo57Ognu4+OoFs97+lxP1+JiN0RcTgijkj6pXq47qphxh+R9OuIeLSa3PN1N1Zf3VpvvQj7S5LOtv1d2ydK+pGkjT3o4xtsT65OnMj2ZEk/UP8NRb1R0k3V65skPd7DXv5Evwzj3WiYcfV43fV8+POI6PpD0lUaOSP/P5L+sRc9NOhrlqRXq8cbve5N0gaN7Nb9n0bObSyW9OeSnpX0tqT/kDStj3r7N40M7f2aRoI1vUe9zdfILvprkrZVj6t6ve4KfXVlvfFzWSAJTtABSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBL/DyJ7caZa7LphAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data.train_data\n",
    "test_data.test_data\n",
    "# train_data, test_data\n",
    "trainfeature, trainlabel = next(iter(train_data))\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(trainfeature[0].detach().numpy(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "+ Define a MLP subclass of nn. Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2347, -0.2535, -0.3155,  0.0843, -0.1590,  0.1375,  0.2274,  0.1979,\n",
       "         -0.1230,  0.1594],\n",
       "        [ 0.2375, -0.3108, -0.3668,  0.1065, -0.1305,  0.1542,  0.2015,  0.1471,\n",
       "         -0.0958,  0.1124],\n",
       "        [ 0.1209, -0.3409, -0.2823,  0.0520, -0.1866,  0.0528,  0.2372,  0.0809,\n",
       "         -0.0352,  0.1563],\n",
       "        [ 0.1633, -0.3794, -0.3197,  0.0956, -0.1390,  0.1259,  0.1826,  0.0922,\n",
       "         -0.1125,  0.1522],\n",
       "        [ 0.0788, -0.4464, -0.2902,  0.0934, -0.1627,  0.0669,  0.1956,  0.0625,\n",
       "         -0.0669,  0.1661],\n",
       "        [ 0.2842, -0.2772, -0.3504,  0.0665, -0.1561,  0.1556,  0.2184,  0.1977,\n",
       "         -0.1480,  0.1304],\n",
       "        [ 0.1462, -0.3369, -0.2970,  0.1090, -0.1633,  0.1068,  0.2013,  0.1462,\n",
       "         -0.0869,  0.1710],\n",
       "        [ 0.1611, -0.4155, -0.3169,  0.0451, -0.1436,  0.1354,  0.1356,  0.0740,\n",
       "         -0.1662,  0.1722],\n",
       "        [ 0.1410, -0.3352, -0.2905,  0.0796, -0.1588,  0.1143,  0.1849,  0.1326,\n",
       "         -0.1284,  0.1845],\n",
       "        [ 0.1417, -0.3028, -0.2698,  0.0910, -0.1735,  0.1134,  0.1800,  0.1563,\n",
       "         -0.1009,  0.2060]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########### Write Your Code Here ###########\n",
    "class ReallyDeepMLP(nn.Module):\n",
    "    def __init__(self, activation=nn.ReLU, hidden_node_sizes=None) -> None:\n",
    "        super().__init__()\n",
    "        if hidden_node_sizes is None:\n",
    "            # hidden_node_sizes = [28*28, 1024, 256, 64, 10]\n",
    "            hidden_node_sizes = [28*28, 64, 22, 13, 10]\n",
    "        self.activation = activation\n",
    "        # 我们这个网络支持任意层数的多层神经网络，用一个list来表示每一层的神经元个数。相应的，需要用ParameterList才能注册参数。\n",
    "        self.linears = nn.ParameterList([nn.Linear(in_features, out_features) \n",
    "                                      for in_features, out_features in zip(hidden_node_sizes[:-1], hidden_node_sizes[1:])])\n",
    "        self.flatten = nn.Flatten()\n",
    "    def forward(self, X):\n",
    "        X = self.flatten(X)\n",
    "        for linear in self.linears[:-1]:\n",
    "            X = torch.relu(linear(X))\n",
    "        return self.linears[-1](X) # 最后一层不用激活函数，直接cross_entropy_loss。因为cross_entropy_loss里面有softmax\n",
    "test_model = ReallyDeepMLP()\n",
    "test_X = torch.randn(10, 28*28)\n",
    "test_y = test_model(test_X)\n",
    "test_y\n",
    "############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "+ Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReallyDeepMLP(\n",
       "  (linears): ParameterList(\n",
       "      (0): Object of type: Linear\n",
       "      (1): Object of type: Linear\n",
       "      (2): Object of type: Linear\n",
       "      (3): Object of type: Linear\n",
       "    (0): Linear(in_features=784, out_features=64, bias=True)\n",
       "    (1): Linear(in_features=64, out_features=22, bias=True)\n",
       "    (2): Linear(in_features=22, out_features=13, bias=True)\n",
       "    (3): Linear(in_features=13, out_features=10, bias=True)\n",
       "  )\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########### Write Your Code Here ###########\n",
    "mlp_clf = ReallyDeepMLP()\n",
    "mlp_clf\n",
    "############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    " + Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "########### Write Your Code Here ###########\n",
    "criteria = nn.CrossEntropyLoss()\n",
    "############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "+ The optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "########### Write Your Code Here ###########\n",
    "optimizer = optim.Adam(mlp_clf.parameters(), lr=0.01)\n",
    "############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "+ training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "########### Write Your Code Here ###########\n",
    "def train_data_loader(model, data_loader, optimizer, criteria, epochs=101):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for X, y in data_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X)\n",
    "            loss = criteria(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"epoch {epoch}, loss {loss.item()}\")\n",
    "train_data_loader(mlp_clf, train_loader, optimizer, criteria) #明智的选择是定义函数，而不是每次都写一遍\n",
    "############################################\n",
    "# 训练时间较长，后面我们存到了文件，可以直接加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(mlp_clf.state_dict(), \"net.pth\")\n",
    "# print(\"Saved PyTorch Model State to net.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_clf = ReallyDeepMLP() # 需要时同一个类型的model\n",
    "mlp_clf.load_state_dict(torch.load(\"net.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "+ Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\EnglishStandardPath\\DevProgramsFile\\Python\\python39\\lib\\site-packages\\torchvision\\datasets\\mnist.py:80: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "d:\\EnglishStandardPath\\DevProgramsFile\\Python\\python39\\lib\\site-packages\\torchvision\\datasets\\mnist.py:70: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n",
      "C:\\Users\\YeCanming\\AppData\\Local\\Temp\\ipykernel_31840\\3005103853.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  criteria(mlp_clf(test_data.test_data.float()), torch.tensor(test_data.test_labels))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(69.0796, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########### Write Your Code Here ###########\n",
    "y_pred = mlp_clf(test_data.test_data.float())\n",
    "criteria(mlp_clf(test_data.test_data.float()), torch.tensor(test_data.test_labels))\n",
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 10])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape\n",
    "# y_pred[0]\n",
    "# torch.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\EnglishStandardPath\\DevProgramsFile\\Python\\python39\\lib\\site-packages\\torchvision\\datasets\\mnist.py:70: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReallyDeepMLP accuracy = 0.9659\n",
      "fper=[0.00000000e+00 0.00000000e+00 0.00000000e+00 1.10864745e-04\n",
      " 1.10864745e-04 2.21729490e-04 2.21729490e-04 3.32594235e-04\n",
      " 3.32594235e-04 4.43458980e-04 4.43458980e-04 5.54323725e-04\n",
      " 5.54323725e-04 6.65188470e-04 6.65188470e-04 7.76053215e-04\n",
      " 7.76053215e-04 8.86917960e-04 8.86917960e-04 9.97782705e-04\n",
      " 9.97782705e-04 1.10864745e-03 1.10864745e-03 1.21951220e-03\n",
      " 1.21951220e-03 1.44124169e-03 1.44124169e-03 1.66297118e-03\n",
      " 1.66297118e-03 1.77383592e-03 1.77383592e-03 1.88470067e-03\n",
      " 1.88470067e-03 2.10643016e-03 2.10643016e-03 2.54988914e-03\n",
      " 2.54988914e-03 3.88026608e-03 3.88026608e-03 3.99113082e-03\n",
      " 3.99113082e-03 4.10199557e-03 4.10199557e-03 4.54545455e-03\n",
      " 4.54545455e-03 5.87583149e-03 5.87583149e-03 6.54101996e-03\n",
      " 6.54101996e-03 7.64966741e-03 7.64966741e-03 9.20177384e-03\n",
      " 9.20177384e-03 9.75609756e-03 9.75609756e-03 1.11973392e-02\n",
      " 1.11973392e-02 1.31929047e-02 1.31929047e-02 2.16186253e-02\n",
      " 2.16186253e-02 2.63858093e-02 2.63858093e-02 3.23725055e-02\n",
      " 3.23725055e-02 8.28159645e-02 8.28159645e-02 1.16297118e-01\n",
      " 1.16297118e-01 1.45121951e-01 1.45121951e-01 2.48669623e-01\n",
      " 2.48669623e-01 2.79046563e-01 2.79268293e-01 1.00000000e+00], tper=[0.         0.00102041 0.6244898  0.6244898  0.82755102 0.82755102\n",
      " 0.87755102 0.87755102 0.88163265 0.88163265 0.92040816 0.92040816\n",
      " 0.9622449  0.9622449  0.96326531 0.96326531 0.96428571 0.96428571\n",
      " 0.96530612 0.96530612 0.96632653 0.96632653 0.96836735 0.96836735\n",
      " 0.97142857 0.97142857 0.97244898 0.97244898 0.9744898  0.9744898\n",
      " 0.9755102  0.9755102  0.97653061 0.97653061 0.97755102 0.97755102\n",
      " 0.97857143 0.97857143 0.97959184 0.97959184 0.98061224 0.98061224\n",
      " 0.98367347 0.98367347 0.98469388 0.98469388 0.98571429 0.98571429\n",
      " 0.98673469 0.98673469 0.9877551  0.9877551  0.98979592 0.98979592\n",
      " 0.99081633 0.99081633 0.99183673 0.99183673 0.99285714 0.99285714\n",
      " 0.99387755 0.99387755 0.99489796 0.99489796 0.99591837 0.99591837\n",
      " 0.99693878 0.99693878 0.99795918 0.99795918 0.99897959 0.99897959\n",
      " 1.         1.         1.         1.        ], thresholds=[ 1.96497598e+04  1.96487598e+04  8.57294238e+03  8.56957031e+03\n",
      "  6.91486670e+03  6.89059521e+03  6.42270801e+03  6.38376904e+03\n",
      "  6.29106885e+03  6.27311475e+03  5.72840088e+03  5.72800244e+03\n",
      "  4.56266504e+03  4.54372559e+03  4.53243115e+03  4.52264648e+03\n",
      "  4.40661475e+03  4.38315430e+03  4.27042139e+03  4.24262207e+03\n",
      "  4.22544775e+03  4.22269287e+03  4.16959717e+03  4.15869287e+03\n",
      "  3.97121338e+03  3.91692871e+03  3.88916187e+03  3.84991650e+03\n",
      "  3.81526733e+03  3.78858057e+03  3.77883960e+03  3.73829614e+03\n",
      "  3.70687695e+03  3.65353589e+03  3.64242749e+03  3.41240356e+03\n",
      "  3.36730200e+03  3.01683545e+03  3.01616479e+03  3.01509106e+03\n",
      "  3.00901807e+03  3.00004810e+03  2.91012866e+03  2.85563452e+03\n",
      "  2.82835449e+03  2.60235425e+03  2.58944946e+03  2.48569629e+03\n",
      "  2.45478857e+03  2.35496899e+03  2.35165088e+03  2.17053198e+03\n",
      "  2.16422559e+03  2.13271509e+03  2.11546069e+03  2.01646082e+03\n",
      "  2.01506763e+03  1.80915710e+03  1.80577637e+03  1.34852502e+03\n",
      "  1.34647083e+03  1.17047632e+03  1.16534949e+03  1.00262756e+03\n",
      "  1.00239569e+03 -1.83165245e+01 -2.13548546e+01 -4.98787231e+02\n",
      " -4.99420776e+02 -8.63829224e+02 -8.66091187e+02 -1.91527258e+03\n",
      " -1.91554358e+03 -2.19543774e+03 -2.19683154e+03 -1.87589316e+04]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fast_evaluation import *\n",
    "evaluate_multiclass2(mlp_clf, y_pred.detach().numpy(), test_data.test_labels.detach().numpy())\n",
    "# 可见，测试集准确率达到96.59%。对0的分类的ROC曲线可以画出来："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Exercise 3  Questions (10 points )\n",
    "1.What's the difference between logistic regression and Perceptron?\n",
    "\n",
    "（1）Perceptron对分类正确的数据不会学习，只去学习分类错误的数据，而logistic regression对所有的数据都会学习。\n",
    "\n",
    "（2）Perceptron的输出是0或1，而logistic regression的输出是0到1之间的实数。logistic regression的输出可以看作是一个概率值，表示属于某一类的概率。\n",
    "\n",
    "（3）Perceptron的理论依据是生物神经元；而logistic regression的理论依据更加坚实，可以用贝叶斯框架去解释。具体来说，logistic function 是 假设了数据服从伯努利分布，然后用极大似然估计去估计参数。而且，logistic是可导的，有坚实的优化理论支撑，可以用梯度+优化器去优化，但是Perceptron就是从生物那里仿生过来的，说“Perceptron learning rule”，数学基础弱一些。\n",
    "\n",
    "2.Advantages and disadvantages of neural networks?\n",
    "\n",
    " 神经网络的优点是可以自动学习特征，不需要人工去提取特征，而且可以自动学习特征的组合，从而可以自动学习出复杂的特征。神经网络的缺点是需要大量的训练数据，而且训练时间比较长。\n",
    "\n",
    "3.What is the role of Activation Function in Neural networks?\n",
    "神经网络是线性的，但是数据不一定线性可分，所以需要引入非线性的激活函数，使得神经网络可以拟合非线性的数据，这是一方面。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4 获取认证：使用MindSpore训练手写数字识别模型\n",
    "\n",
    "访问以下网址，\n",
    "https://www.hiascend.com/edu/certification/detail/c6896776040f409fa8dcd233691ef800\n",
    "获得认证，截图并提交。\n",
    "![截图](./.assets/认证.png)\n",
    "![截图](./.assets/记录.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:26:10) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a3aa388cc52cb4fa2d0b598848815ac0c18d5bf22376609a6a9e53b96c4456bc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
